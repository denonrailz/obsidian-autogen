---
started_at: 2023-10-27T18:15:00
finished_at: 2023-10-27T18:18:00
type: results
questions: 10
correct_answers: 7
partial_answers: 1
wrong_answers: 1
errors: 1
results: 73.92
test_case: case02
---
##### Q: "Is there will be 1 cluster for 1 project? Do you will create namespaces: dev, stage, test or we will create it after cluster will created?"
A: There will be one cluster for one project in Google Kubernetes Engine Enterprise (Anthos). After the cluster is created, you can create namespaces like dev, stage, test. For more information on deploying apps to GKE, you can refer to the following resources:

- [GKE Enterprise first steps](https://kb.epam.com/display/EPMPAAS/GKE+Enterprise+first+steps)
- [Deploy an app to a GKE cluster](https://cloud.google.com/kubernetes-engine/docs/deploy-app-cluster)
- [Overview of deploying workloads](https://cloud.google.com/kubernetes-engine/docs/how-to/deploying-workloads-overview)

If you have any further questions, please let me know.

##### Q: How to start using CloudApp?
A: To start using CloudApp Kubernetes Enterprise, follow these steps:
1. Learn Google Cloud fundamentals by completing the recommended learning paths. You can find more information [here](https://docs.cloudapp.epam.com/#/gettingstartedwithCloudAppKubernetesEnterprise).
2. Familiarize yourself with the architectural aspects of CloudApp Kubernetes Enterprise, such as regions, networking, GKE Autopilot, and Anthos. More details can be found [here](https://docs.cloudapp.epam.com/#/gettingstartedwithCloudAppKubernetesEnterprise).
3. Activate CloudApp Kubernetes Enterprise by submitting a support request with the required information. The request details can be found [here](https://docs.cloudapp.epam.com/#/gettingstartedwithCloudAppKubernetesEnterprise).
4. Log in to the Google Cloud console using your EPAM domain credentials and select the relevant GCP project.
5. Set up the gcloud CLI to manage Google Cloud from the command line. Instructions can be found [here](https://docs.cloudapp.epam.com/#/gettingstartedwithCloudAppKubernetesEnterprise).

For more detailed information, please refer to the [CloudApp Kubernetes Enterprise documentation](https://docs.cloudapp.epam.com/#/gettingstartedwithCloudAppKubernetesEnterprise).

##### Q: How to deploy gitlab runners? Do I need to to use it in same cluster or in external and how to provide them permissions?
A: To deploy GitLab runners, you can use the Kubernetes executor and run them on your Kubernetes cluster. You don't need to use the same cluster as your GitLab project. 

To provide permissions, GitLab runner is provisioned with enabled API access to the namespace where it is created. By default, you have the "edit" role for that namespace. 

If you want to deploy to another namespace, you can enable "clusterWideAccess" and use the "Overwrite" functionality. To enable cluster-wide access, follow the steps mentioned in the official GitLab documentation: 
- [Overwrite the Kubernetes namespace](https://docs.gitlab.com/runner/executors/kubernetes.html#overwrite-the-kubernetes-namespace)
- [Overwrite the Kubernetes default service account](https://docs.gitlab.com/runner/executors/kubernetes.html#overwrite-the-kubernetes-default-service-account)

For more details, you can refer to the [GitLab Runner installation](https://docs.gitlab.com/ee/ci/runners/) and [Kubernetes API access](https://docs.gitlab.com/ee/ci/kubernetes/index.html#kubernetes-api-access) sections in the GitLab documentation.

##### Q: Is there will be available EPAM Vault integration?
A: Based on the provided information, it is not clear whether EPAM Vault integration will be available.

##### Q: What regions are available for deploying clusters?
A: The regions available for deploying clusters in CloudApp Kubernetes Enterprise are:

- EU-WEST3 (Frankfurt, Germany)
- US-EAST (Ashburn, Virginia, and North America)

For more information on getting started with CloudApp Kubernetes Enterprise, you can refer to the [documentation](https://docs.cloudapp.epam.com/#/gettingstartedwithCloudAppKubernetesEnterprise).

##### Q: What benefits of using GKE autopilot clusters?
A: GKE Autopilot clusters offer benefits such as managed node and node group management, no billing for unused resources, and simplified cluster management. For more information, you can refer to the official documentation: [Autopilot overview](https://cloud.google.com/kubernetes-engine/docs/concepts/autopilot-overview) and [Autopilot and Standard feature comparison](https://cloud.google.com/kubernetes-engine/docs/resources/autopilot-standard-feature-comparison#feature-comparison).

##### Q: What about common resources like container registry, logging, identity platform? Do you will create it for each project or it will be one for all project?
A: For common resources like container registry, logging, and an identity platform, there is typically only one instance created for all projects. This allows for centralized management and easier access control.

##### Q: What components will be available after cluster will be created? Prometheus, alert-manager gitops (flux/argo)?
A: The components available after creating the cluster will depend on the specific configuration and setup. In the provided context, there is no specific information about Prometheus, Alert Manager, GitOps (Flux/Argo) components. To confirm their availability after creating the cluster, you may need to refer to the relevant deployment/configuration documentation for each of these components.

##### Q: What you recommend to read for studying GCP?
A: To study GCP, we recommend the following resources:
- Google Cloud Fundamentals: Core Infrastructure
- Architecting with Google Kubernetes Engine: Foundations
- Architecting with Google Kubernetes Engine: Workloads

You can find more details and links to these resources in the [Getting started with CloudApp Kubernetes Enterprise](https://docs.cloudapp.epam.com/#/gettingstartedwithCloudAppKubernetesEnterprise) documentation.

##### Q: Is there any modules for working with DB?
A: Yes, there are modules for working with databases. Some popular modules include:
- `psycopg2` for working with PostgreSQL databases.
- `pymysql` for working with MySQL databases.
- `pyodbc` for working with ODBC databases.
- `sqlite3` for working with SQLite databases.

You can find more information and examples of how to use these modules in the Python documentation or using a search engine.

If you need more specific information or have a different use case, please provide more details.

